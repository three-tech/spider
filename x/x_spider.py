#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆXå¹³å°çˆ¬è™« - åŸºäºtwitter-openapi-typescriptçš„Pythonå®ç°
å‚è€ƒ: /Users/xuzongxin/workspace/other/XT-Bot/TypeScript/scripts/fetch-tweets.ts
"""

import json
import logging
import os
import sys
import time
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Generator

from x.x_auth_client import create_x_auth_client

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ç°åœ¨å¯¼å…¥baseæ¨¡å—
from base.database import DatabaseManager


class XSpider:
    def __init__(self):
        """åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆXå¹³å°çˆ¬è™«"""
        # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†å™¨
        self.logger = None
        from base.config import config
        self.config = config
        self.db_manager = None
        self.twitter_client = None
        # å…ˆè®¾ç½®æ—¥å¿—
        self.setup_logging()
        self.setup_database()
        self.setup_twitter_client()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿— - ä½¿ç”¨ç»Ÿä¸€çš„ç»“æ„åŒ–æ—¥å¿—ç³»ç»Ÿ"""
        from base.logger import get_logger
        self.logger = get_logger(self.__class__.__name__)
        return self.logger

    def setup_database(self):
        """è®¾ç½®æ•°æ®åº“è¿æ¥"""
        try:
            db_config = self.config.get("database", {})
            self.db_manager = DatabaseManager(
                host=db_config.get("host", "localhost"),
                port=db_config.get("port", 3306),
                user=db_config.get("user", "root"),
                password=db_config.get("password", "123456"),
                database=db_config.get("database", "resource")
            )
            self.logger.info("æ•°æ®åº“è¿æ¥åˆå§‹åŒ–æˆåŠŸ", component="database")
        except Exception as e:
            self.logger.error("æ•°æ®åº“è¿æ¥åˆå§‹åŒ–å¤±è´¥", error=str(e))
            self.db_manager = None
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸ç¨‹åºç»§ç»­è¿è¡Œä½†æ— æ³•ä½¿ç”¨æ•°æ®åº“åŠŸèƒ½

    def setup_twitter_client(self):
        """è®¾ç½®Xè®¤è¯å®¢æˆ·ç«¯"""
        try:
            # ä»ç»Ÿä¸€é…ç½®ä¸­è·å–Xå¹³å°é…ç½®
            auth_token = self.config.get_x_config().get('auth_token')

            if not auth_token:
                self.logger.error("æœªé…ç½®auth_tokenï¼Œæ— æ³•åˆå§‹åŒ–Xå®¢æˆ·ç«¯", component="authentication")
                self.twitter_client = None
                return

            self.twitter_client = create_x_auth_client(auth_token)
            self.logger.info("Xè®¤è¯å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ", component="authentication")

        except Exception as e:
            self.logger.error("Xè®¤è¯å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥", error=str(e))
            self.twitter_client = None

    def get_user_info(self, screen_name: str, force_refresh: bool = False) -> Optional[Dict[str, str]]:
        """è·å–ç”¨æˆ·ä¿¡æ¯ - ä¼˜å…ˆä»member_xè¡¨è·å–ï¼Œç„¶åæ˜¯æ–‡ä»¶ç¼“å­˜ï¼Œæœ€åè°ƒç”¨API"""
        try:
            # æ­¥éª¤1: ä¼˜å…ˆä»æ•°æ®åº“member_xè¡¨è·å–
            if not force_refresh and self.db_manager:
                cached_user = self.db_manager.get_member_by_screen_name(screen_name)
                if cached_user:
                    self.logger.info("ä»æ•°æ®åº“ç¼“å­˜è·å–ç”¨æˆ·ä¿¡æ¯", screen_name=screen_name)
                    return {
                        "screenName": cached_user.screen_name,
                        "userId": str(cached_user.user_id),
                        "name": cached_user.name
                    }

            # æ­¥éª¤2: å°è¯•è¯»å–æ–‡ä»¶ç¼“å­˜
            cache_dir = "../resp/cache"
            os.makedirs(cache_dir, exist_ok=True)
            cache_path = os.path.join(cache_dir, f"{screen_name}.json")

            if not force_refresh and os.path.exists(cache_path):
                try:
                    with open(cache_path, 'r', encoding='utf-8') as f:
                        cached = json.load(f)
                    if cached.get('userId'):
                        self.logger.info("ä½¿ç”¨æ–‡ä»¶ç¼“å­˜ç”¨æˆ·ä¿¡æ¯", screen_name=screen_name)
                        return cached
                except Exception as e:
                    logging.warning(f"è¯»å–æ–‡ä»¶ç¼“å­˜å¤±è´¥: {e}")

            # æ­¥éª¤3: è°ƒç”¨APIè·å–æ–°æ•°æ®
            self.logger.info("æ­£åœ¨è¯·æ±‚APIè·å–ç”¨æˆ·ä¿¡æ¯", screen_name=screen_name)

            # æ„å»ºAPIè¯·æ±‚
            user_info = self._fetch_user_by_screen_name(screen_name)

            if not user_info:
                raise Exception(f"æœªæ‰¾åˆ°ç”¨æˆ· @{screen_name}")

            # æ­¥éª¤4: ä¿å­˜åˆ°æ•°æ®åº“ç¼“å­˜
            try:
                # è·å–å®Œæ•´çš„ç”¨æˆ·æ•°æ®ç”¨äºä¿å­˜åˆ°æ•°æ®åº“
                full_user_data = self.twitter_client.get_user_by_screen_name(screen_name)
                if full_user_data and self.db_manager:
                    save_success = self.db_manager.save_member(full_user_data)
                    if save_success:
                        self.logger.info("ç”¨æˆ·ä¿¡æ¯å·²ä¿å­˜åˆ°æ•°æ®åº“ç¼“å­˜", screen_name=screen_name)
                    else:
                        self.logger.warning("ç”¨æˆ·ä¿¡æ¯ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥", screen_name=screen_name)
            except Exception as e:
                self.logger.warning("ä¿å­˜ç”¨æˆ·ä¿¡æ¯åˆ°æ•°æ®åº“æ—¶å‡ºé”™", error=str(e))

            # æ­¥éª¤5: å†™å…¥æ–‡ä»¶ç¼“å­˜
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(user_info, f, ensure_ascii=False, indent=2)

            self.logger.info("è·å–ç”¨æˆ·ä¿¡æ¯æˆåŠŸ",
                             screen_name=user_info['screenName'],
                             user_id=user_info['userId'])
            return user_info

        except Exception as e:
            self.logger.error("è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥", error=str(e))
            return None

    def _fetch_user_by_screen_name(self, screen_name: str) -> Optional[Dict[str, str]]:
        """é€šè¿‡ç”¨æˆ·åè·å–ç”¨æˆ·ä¿¡æ¯ - ä½¿ç”¨Xè®¤è¯å®¢æˆ·ç«¯"""
        try:
            if not self.twitter_client:
                self.logger.error("Xè®¤è¯å®¢æˆ·ç«¯æœªåˆå§‹åŒ–", component="authentication")
                return None

            # ä½¿ç”¨Xè®¤è¯å®¢æˆ·ç«¯è·å–ç”¨æˆ·ä¿¡æ¯
            user_data = self.twitter_client.get_user_by_screen_name(screen_name)

            if user_data and user_data.get('id_str'):
                return {
                    "screenName": user_data.get('screen_name', screen_name),
                    "userId": user_data.get('id_str', ''),
                    "name": user_data.get('name', screen_name)
                }
            else:
                self.logger.error("æœªæ‰¾åˆ°ç”¨æˆ·", screen_name=screen_name)
                return None

        except Exception as e:
            self.logger.error("è·å–ç”¨æˆ·ä¿¡æ¯å¼‚å¸¸", error=str(e))
            return None

    def transform_tweet(self, item: Dict[str, Any], user_id: str, filter_retweets: bool = True,
                        filter_quotes: bool = True) -> Optional[Dict[str, Any]]:
        """è½¬æ¢æ¨æ–‡æ•°æ® - å¢å¼ºè½¬å‘æ¨æ–‡å¤„ç†åŠŸèƒ½"""
        try:
            # å¿«é€Ÿå¤±è´¥æ£€æŸ¥
            if not self._should_process_tweet(item, filter_retweets, filter_quotes):
                return None

            # æå–åŸºç¡€ä¿¡æ¯
            full_text = self._safe_get(item, 'legacy.full_text', '')
            publish_time = self._get_publish_time(item)
            user_info = self._extract_user_info(item)

            # æ£€æŸ¥å¿…è¦å­—æ®µ
            if not self._has_required_fields(user_info, full_text):
                return None

            # æå–åª’ä½“å’ŒURL
            media_data = self._extract_media_data(item)
            tweet_url = self._build_tweet_url(user_info, item)

            logging.info(f"âœ… è½¬æ¢æˆåŠŸ: {tweet_url}")

            return {
                "screenName": user_info["screenName"],
                "images": media_data["images"],
                "videos": media_data["videos"],
                "tweetUrl": tweet_url,
                "fullText": full_text,
                "publishTime": publish_time
            }

        except Exception as e:
            logging.error(f"è½¬æ¢æ¨æ–‡æ•°æ®å¤±è´¥: {e}")
            return None

    def _is_valid_tweet_structure(self, item: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ¨æ–‡æ•°æ®ç»“æ„æ˜¯å¦æœ‰æ•ˆ"""
        if not isinstance(item, dict):
            return False

        logging.debug(f"æ¨æ–‡æ•°æ®é”®: {list(item.keys())}")
        if 'legacy' in item:
            logging.debug(f"legacyé”®: {list(item['legacy'].keys())}")

        return True

    def _should_process_tweet(self, item: Dict[str, Any], filter_retweets: bool, filter_quotes: bool) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†æ¨æ–‡ - å¿«é€Ÿå¤±è´¥ç­–ç•¥"""
        # æ£€æŸ¥æ•°æ®ç»“æ„
        if not self._is_valid_tweet_structure(item):
            return False

        full_text = self._safe_get(item, 'legacy.full_text', '')

        # è¿‡æ»¤è½¬æ¨
        if filter_retweets and full_text.strip().startswith("RT @"):
            return False

        # è¿‡æ»¤å¼•ç”¨æ¨æ–‡
        if filter_quotes and self._safe_get(item, 'legacy.is_quote_status', False):
            return False

        return True

    def _safe_get(self, obj: Dict[str, Any], path: str, default_value: Any = '') -> Any:
        """å®‰å…¨è·å–åµŒå¥—å­—å…¸å€¼"""
        keys = path.split('.')
        value = obj
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default_value
        return value

    def _get_publish_time(self, item: Dict[str, Any]) -> str:
        """è·å–å‘å¸ƒæ—¶é—´"""
        created_at = self._safe_get(item, 'legacy.created_at', '')
        publish_time = self.convert_to_beijing_time(created_at)

        if not publish_time:
            logging.warning(f"ğŸ•’ æ—¶é—´è§£æå¤±è´¥: {created_at}")
            publish_time = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')

        return publish_time

    def _extract_user_info(self, item: Dict[str, Any]) -> Dict[str, str]:
        """æå–ç”¨æˆ·ä¿¡æ¯"""
        return {
            "screenName": self._safe_get(item, 'core.user_results.result.legacy.screen_name', ''),
            "name": self._safe_get(item, 'core.user_results.result.legacy.name', '')
        }

    def _has_required_fields(self, user_info: Dict[str, str], full_text: str) -> bool:
        """æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨"""
        if not user_info["screenName"] or not full_text:
            logging.warning(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µ - screenName: {user_info['screenName']}, full_text: {bool(full_text)}")
            return False
        return True

    def _extract_media_data(self, item: Dict[str, Any]) -> Dict[str, List[str]]:
        """æå–åª’ä½“æ•°æ®"""
        media_items = self._extract_all_media_items(item)
        images = self._extract_images(media_items)
        videos = self._extract_videos(media_items)

        return {
            "images": images,
            "videos": videos
        }

    def _extract_all_media_items(self, item: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æå–æ‰€æœ‰åª’ä½“é¡¹ç›®"""
        # ä¼˜å…ˆå°è¯•æ‰©å±•åª’ä½“å®ä½“
        media_items = self._safe_get(item, 'legacy.extended_entities.media', [])

        # å¦‚æœä¸ºç©ºï¼Œå°è¯•åŸºç¡€åª’ä½“å®ä½“
        if not media_items:
            media_items = self._safe_get(item, 'legacy.entities.media', [])

        # å¦‚æœæ˜¯è½¬å‘æ¨æ–‡ä¸”éœ€è¦å¤„ç†è½¬å‘åª’ä½“
        if self._should_extract_retweet_media(item):
            retweet_media = self._extract_retweet_media(item)
            if retweet_media:
                media_items = retweet_media
                logging.debug("ğŸ”„ ä»è½¬å‘æºæ¨æ–‡æå–åª’ä½“å†…å®¹")

        return media_items

    def _should_extract_retweet_media(self, item: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æå–è½¬å‘æ¨æ–‡çš„åª’ä½“"""
        full_text = self._safe_get(item, 'legacy.full_text', '')
        is_retweet = full_text.strip().startswith("RT @")

        if not is_retweet or not self.db_manager:
            return False

        user_info = self._extract_user_info(item)
        db_user = self.db_manager.get_member_by_screen_name(user_info["screenName"])

        return db_user and db_user.process_retweets

    def _extract_retweet_media(self, item: Dict[str, Any]) -> Optional[List[Dict[str, Any]]]:
        """ä»è½¬å‘æºæ¨æ–‡æå–åª’ä½“"""
        retweeted_status = self._safe_get(item, 'legacy.retweeted_status_result.result', {})
        if not retweeted_status:
            return None

        # å°è¯•æ‰©å±•åª’ä½“å®ä½“
        retweet_media = self._safe_get(retweeted_status, 'legacy.extended_entities.media', [])
        if not retweet_media:
            retweet_media = self._safe_get(retweeted_status, 'legacy.entities.media', [])

        return retweet_media if retweet_media else None

    def _extract_images(self, media_items: List[Dict[str, Any]]) -> List[str]:
        """æå–å›¾ç‰‡URL"""
        images = []
        for media in media_items:
            if media.get('type') == 'photo':
                media_url = media.get('media_url_https')
                if media_url:
                    images.append(media_url)
                    logging.debug(f"ğŸ“¸ æå–å›¾ç‰‡: {media_url}")
        return images

    def _extract_videos(self, media_items: List[Dict[str, Any]]) -> List[str]:
        """æå–è§†é¢‘URL"""
        videos = []
        for media in media_items:
            if media.get('type') in ['video', 'animated_gif']:
                video_url = self._extract_best_video_url(media)
                if video_url:
                    videos.append(video_url)
        return videos

    def _extract_best_video_url(self, media: Dict[str, Any]) -> Optional[str]:
        """æå–æœ€ä½³è´¨é‡çš„è§†é¢‘URL"""
        video_info = media.get('video_info', {})
        variants = video_info.get('variants', [])

        mp4_variants = [v for v in variants if v.get('content_type') == 'video/mp4']
        if not mp4_variants:
            return None

        best_variant = max(mp4_variants, key=lambda x: x.get('bitrate', 0))
        logging.debug(f"ğŸ¬ æå–è§†é¢‘: {best_variant['url'][:50]}...")
        return best_variant['url']

    def _extract_urls(self, item: Dict[str, Any]) -> List[str]:
        """æå–æ‰©å±•URL"""
        expand_urls = []
        urls = self._safe_get(item, 'legacy.entities.urls', [])
        for url in urls:
            expanded_url = url.get('expandedUrl')
            if expanded_url:
                expand_urls.append(expanded_url)
        return expand_urls

    def _build_tweet_url(self, user_info: Dict[str, str], item: Dict[str, Any]) -> str:
        """æ„é€ æ¨æ–‡URL"""
        tweet_id = self._safe_get(item, 'legacy.id_str', '') or self._safe_get(item, 'rest_id', '')
        return f"https://x.com/{user_info['screenName']}/status/{tweet_id}"

    def convert_to_beijing_time(self, date_str: str) -> Optional[str]:
        """è½¬æ¢åˆ°åŒ—äº¬æ—¶é—´"""
        try:
            if not date_str:
                return None

            # å°è¯•è§£æTwitteræ—¶é—´æ ¼å¼
            # ä¾‹: "Wed Oct 10 20:19:24 +0000 2018"
            dt = datetime.strptime(date_str, "%a %b %d %H:%M:%S %z %Y")

            # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ (UTC+8)
            from datetime import timedelta
            beijing_tz = timezone(timedelta(hours=8))
            beijing_time = dt.astimezone(beijing_tz)

            return beijing_time.strftime('%Y-%m-%dT%H:%M:%S')

        except Exception as e:
            logging.warning(f"æ—¶é—´è½¬æ¢å¤±è´¥: {e}")
            # è¿”å›å½“å‰æ—¶é—´ä½œä¸ºå¤‡é€‰
            return datetime.now().strftime('%Y-%m-%dT%H:%M:%S')

    def tweet_cursor_generator(self, user_id: str, limit: int = 50, content_type: str = 'tweets') -> Generator[
        Dict[str, Any], None, None]:
        """åˆ†é¡µç”Ÿæˆå™¨ - æ¨¡æ‹ŸAPIåˆ†é¡µè¯·æ±‚"""
        cursor = None
        count = 0
        empty_count = 0
        page_count = 0

        while count < limit:
            page_count += 1
            logging.info(f"\n=== ç¬¬ {page_count} æ¬¡è¯·æ±‚ ===")
            logging.info(f"â±ï¸ è¯·æ±‚æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            logging.info(f"ğŸ¯ ç›®æ ‡ç”¨æˆ·ID: {user_id}")

            if cursor:
                logging.info(f"ğŸ“ å½“å‰æ¸¸æ ‡: {cursor}")

            # è¯·æ±‚é—´éš”
            if page_count > 1:
                x_config = self.config.get('x', {})
                interval = x_config.get("delay_between_requests", 2)
                logging.info(f"â¸ï¸ ç­‰å¾… {interval} ç§’...")
                time.sleep(interval)

            # çœŸå®APIè¯·æ±‚
            try:
                response_data = self.api_request_tweets(user_id, cursor, content_type)
                tweets = response_data.get('data', [])
                new_cursor = response_data.get('cursor')

                logging.info(f"ğŸ”„ è·å–åˆ° {len(tweets)} æ¡æ¨æ–‡")

                if len(tweets) == 0:
                    empty_count += 1
                    logging.info(f"âŒ ç©ºæ•°æ®è®¡æ•°: {empty_count}/3")
                    if empty_count >= 3:
                        logging.info("â¹ï¸ ç»ˆæ­¢åŸå› ï¼šè¿ç»­3æ¬¡ç©ºå“åº”")
                        break
                else:
                    empty_count = 0

                # å¤„ç†æ•°æ®
                for item in tweets:
                    yield item
                    count += 1
                    if count >= limit:
                        logging.info(f"â¹ï¸ ç»ˆæ­¢åŸå› ï¼šè¾¾åˆ°æ•°é‡é™åˆ¶ï¼ˆ{limit}ï¼‰")
                        return

                cursor = new_cursor
                if not cursor:
                    logging.info("â¹ï¸ ç»ˆæ­¢åŸå› ï¼šæ— æ›´å¤šæ•°æ®")
                    break

            except Exception as e:
                logging.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
                break

        logging.info(f"ğŸ“Œ ç´¯è®¡å·²å¤„ç†: {count} æ¡")

    def api_request_tweets(self, user_id: str, cursor: Optional[str], content_type: str) -> Dict[str, Any]:
        """çœŸå®çš„APIè¯·æ±‚ - è·å–ç”¨æˆ·æ¨æ–‡"""
        try:
            if not self.twitter_client:
                logging.error("Xè®¤è¯å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return {"data": [], "cursor": None}

            # ä½¿ç”¨Xè®¤è¯å®¢æˆ·ç«¯è·å–æ¨æ–‡
            response = self.twitter_client.get_user_tweets(user_id, cursor, count=20)

            if response:
                return response
            else:
                logging.warning("APIè¿”å›ç©ºå“åº”")
                return {"data": [], "cursor": None}

        except Exception as e:
            logging.error(f"APIè¯·æ±‚å¤±è´¥: {e}")
            return {"data": [], "cursor": None}

    def process_user_tweets(self, user_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å¤„ç†ç”¨æˆ·æ¨æ–‡çš„ä¸»æµç¨‹ - æ”¯æŒå¢é‡çˆ¬å–å’Œç”¨æˆ·çº§é…ç½®"""
        screen_name = user_config['screen_name']
        start_time = time.time()
        self.logger.info("=" * 60)
        self.logger.info(f"ğŸš€ å¼€å§‹å¤„ç†ç”¨æˆ· @{screen_name}")

        try:
            # å¿«é€Ÿå¤±è´¥ï¼šè·å–ç”¨æˆ·ä¿¡æ¯
            user_info = self._get_user_info_for_processing(screen_name)
            if not user_info:
                return []

            # è·å–çˆ¬å–é…ç½® (ç°åœ¨åŸºäºç”¨æˆ·é…ç½®)
            crawl_config = self._prepare_crawl_config(user_config)
            if not crawl_config:
                return []

            # å¤„ç†æ¨æ–‡æ•°æ®
            all_tweets = self._process_tweets_with_incremental_crawl(user_info, crawl_config)

            # ä¿å­˜ç»“æœå¹¶æ›´æ–°çŠ¶æ€
            self._save_and_update_crawl_info(screen_name, all_tweets, start_time, user_info)

            return all_tweets

        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†ç”¨æˆ· @{screen_name} å¤±è´¥", error=str(e))
            return []

    def _get_user_info_for_processing(self, screen_name: str) -> Optional[Dict[str, Any]]:
        """è·å–ç”¨æˆ·ä¿¡æ¯ - å¿«é€Ÿå¤±è´¥"""
        force_refresh = self.config.get_x_config().get('force_refresh', False)
        user_info = self.get_user_info(screen_name, force_refresh)

        if not user_info:
            logging.error(f"æ— æ³•è·å–ç”¨æˆ· @{screen_name} çš„ä¿¡æ¯")
            return None

        return user_info

    def _prepare_crawl_config(self, user_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æ ¹æ®ç”¨æˆ·é…ç½®å‡†å¤‡çˆ¬å–å‚æ•°"""
        screen_name = user_config['screen_name']
        last_tweet_time = self._get_last_crawl_time(screen_name)

        # process_retweets: 0=ä¸å¤„ç†(è¿‡æ»¤), 1=å¤„ç†(ä¸è¿‡æ»¤)
        # filter_retweets: True=è¿‡æ»¤, False=ä¸è¿‡æ»¤
        # å› æ­¤ filter_retweets = not process_retweets
        process_retweets = bool(user_config.get("process_retweets", False))
        filter_retweets = not process_retweets
        filter_quotes = bool(user_config.get("filter_quotes", True))

        self.logger.info("åº”ç”¨ç”¨æˆ·çº§çˆ¬å–é…ç½®",
                         username=screen_name,
                         process_retweets=process_retweets,
                         filter_retweets=filter_retweets,
                         filter_quotes=filter_quotes)

        return {
            "max_tweets": self.config.get_x_config().get("max_tweets_per_user", 50),
            "filter_retweets": filter_retweets,
            "filter_quotes": filter_quotes,
            "content_type": "tweets",
            "last_tweet_time": last_tweet_time
        }

    def _get_last_crawl_time(self, screen_name: str) -> Optional[datetime]:
        """è·å–ä¸Šæ¬¡çˆ¬å–æ—¶é—´"""
        if not self.db_manager:
            logging.info("ğŸ†• æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œè·å–æ‰€æœ‰æ¨æ–‡")
            return None

        crawl_info = self.db_manager.get_user_last_crawl_info(screen_name)
        if crawl_info and 'last_tweet_time' in crawl_info:
            last_tweet_time = crawl_info['last_tweet_time']
            logging.info(f"ğŸ“… ä¸Šæ¬¡çˆ¬å–çš„æœ€æ–°æ¨æ–‡æ—¶é—´: {last_tweet_time}")
            logging.info("ğŸ”„ å¯ç”¨å¢é‡çˆ¬å–æ¨¡å¼ï¼Œåªè·å–æ–°æ¨æ–‡")
            return last_tweet_time
        else:
            logging.info("ğŸ†• é¦–æ¬¡çˆ¬å–è¯¥ç”¨æˆ·ï¼Œè·å–æ‰€æœ‰æ¨æ–‡")
            return None

    def _process_tweets_with_incremental_crawl(self, user_info: Dict[str, Any],
                                               crawl_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å¤„ç†æ¨æ–‡æ•°æ®ï¼Œæ”¯æŒå¢é‡çˆ¬å–"""
        all_tweets = []
        new_tweets_count = 0
        latest_tweet_time = None
        last_tweet_time = crawl_config.get("last_tweet_time")

        for item in self.tweet_cursor_generator(user_info['userId'],
                                                crawl_config["max_tweets"],
                                                crawl_config["content_type"]):

            # å¤„ç†å•ä¸ªæ¨æ–‡é¡¹ç›®
            tweet_data = self._process_single_tweet_item(item, user_info, crawl_config)
            if not tweet_data:
                continue

            # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢çˆ¬å–
            if self._should_stop_crawling(tweet_data, last_tweet_time, latest_tweet_time):
                break

            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            all_tweets.append(tweet_data)
            new_tweets_count = self._update_new_tweets_count(tweet_data, last_tweet_time, new_tweets_count)
            latest_tweet_time = self._update_latest_tweet_time(tweet_data, latest_tweet_time)

        logging.info(f"ğŸ“Š å¤„ç†å®Œæˆ - æœ‰æ•ˆæ¨æ–‡: {len(all_tweets)}, æ–°æ¨æ–‡: {new_tweets_count}")
        return all_tweets

    def _process_single_tweet_item(self, item: Dict[str, Any], user_info: Dict[str, Any],
                                   crawl_config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """å¤„ç†å•ä¸ªæ¨æ–‡é¡¹ç›®"""
        tweet_data = self.transform_tweet(
            item,
            user_info['userId'],
            crawl_config["filter_retweets"],
            crawl_config["filter_quotes"]
        )

        return tweet_data if tweet_data else None

    def _should_stop_crawling(self, tweet_data: Dict[str, Any], last_tweet_time: Optional[datetime],
                              latest_tweet_time: Optional[datetime]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥åœæ­¢çˆ¬å–"""
        if not last_tweet_time:
            return False

        tweet_time = self._parse_tweet_time(tweet_data.get('publishTime', ''))
        if not tweet_time:
            return False

        # å¦‚æœæ¨æ–‡æ—¶é—´æ—©äºæˆ–ç­‰äºä¸Šæ¬¡çˆ¬å–æ—¶é—´ï¼Œåœæ­¢çˆ¬å–
        if tweet_time <= last_tweet_time:
            logging.info(f"â¹ï¸ é‡åˆ°å·²çˆ¬å–çš„æ¨æ–‡ ({tweet_data.get('publishTime', '')})ï¼Œåœæ­¢çˆ¬å–")
            return True

        return False

    def _parse_tweet_time(self, time_str: str) -> Optional[datetime]:
        """è§£ææ¨æ–‡æ—¶é—´"""
        if not time_str:
            return None

        try:
            return datetime.strptime(time_str, '%Y-%m-%dT%H:%M:%S')
        except ValueError as e:
            logging.warning(f"âš ï¸ æ¨æ–‡æ—¶é—´è§£æå¤±è´¥: {time_str}, {e}")
            return None

    def _update_new_tweets_count(self, tweet_data: Dict[str, Any], last_tweet_time: Optional[datetime],
                                 current_count: int) -> int:
        """æ›´æ–°æ–°æ¨æ–‡è®¡æ•°"""
        if not last_tweet_time:
            return current_count + 1

        tweet_time = self._parse_tweet_time(tweet_data.get('publishTime', ''))
        if tweet_time and tweet_time > last_tweet_time:
            return current_count + 1

        return current_count

    def _update_latest_tweet_time(self, tweet_data: Dict[str, Any], current_latest: Optional[datetime]) -> Optional[
        datetime]:
        """æ›´æ–°æœ€æ–°æ¨æ–‡æ—¶é—´"""
        tweet_time = self._parse_tweet_time(tweet_data.get('publishTime', ''))
        if not tweet_time:
            return current_latest

        if not current_latest or tweet_time > current_latest:
            return tweet_time

        return current_latest

    def _save_and_update_crawl_info(self, screen_name: str, all_tweets: List[Dict[str, Any]],
                                    start_time: float, user_info: Dict[str, Any]):
        """ä¿å­˜æ•°æ®å¹¶æ›´æ–°çˆ¬å–ä¿¡æ¯"""
        # ä¿å­˜æ¨æ–‡åˆ°æ•°æ®åº“
        success_count = self.save_tweets_to_database(all_tweets) if all_tweets else 0
        logging.info(f"âœ… æˆåŠŸä¿å­˜ {success_count} æ¡æ¨æ–‡åˆ°æ•°æ®åº“")

        # æ›´æ–°çˆ¬å–ä¿¡æ¯
        self._update_crawl_info(screen_name, all_tweets)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self._log_processing_stats(screen_name, all_tweets, success_count, start_time, user_info)

    def _update_crawl_info(self, screen_name: str, all_tweets: List[Dict[str, Any]]):
        """æ›´æ–°çˆ¬å–ä¿¡æ¯"""
        if not self.db_manager:
            logging.warning("âš ï¸ æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ›´æ–°çˆ¬å–ä¿¡æ¯")
            return

        latest_tweet_time = self._get_latest_tweet_time_from_list(all_tweets)
        if latest_tweet_time:
            self.db_manager.update_user_crawl_info(screen_name, latest_tweet_time)
            logging.info(f"ğŸ“ æ›´æ–°ç”¨æˆ·æœ€æ–°æ¨æ–‡æ—¶é—´: {latest_tweet_time}")
        else:
            self.db_manager.update_user_crawl_info(screen_name)
            logging.info("ğŸ“ æ›´æ–°ç”¨æˆ·çˆ¬å–æ—¶é—´")

    def _get_latest_tweet_time_from_list(self, tweets: List[Dict[str, Any]]) -> Optional[datetime]:
        """ä»æ¨æ–‡åˆ—è¡¨ä¸­è·å–æœ€æ–°æ—¶é—´"""
        latest_time = None
        for tweet in tweets:
            tweet_time = self._parse_tweet_time(tweet.get('publishTime', ''))
            if tweet_time and (not latest_time or tweet_time > latest_time):
                latest_time = tweet_time
        return latest_time

    def _log_processing_stats(self, screen_name: str, all_tweets: List[Dict[str, Any]],
                              success_count: int, start_time: float, user_info: Dict[str, Any]):
        """è®°å½•å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        time_cost = (time.time() - start_time)
        latest_tweet_time = self._get_latest_tweet_time_from_list(all_tweets)

        logging.info(f"""
ğŸ‰ å¤„ç†å®Œæˆï¼
â”œâ”€â”€ ç”¨æˆ·ï¼š@{user_info['screenName']} (ID: {user_info['userId']})
â”œâ”€â”€ è·å–ï¼š{len(all_tweets)} æ¡æœ‰æ•ˆæ¨æ–‡
â”œâ”€â”€ ä¿å­˜ï¼š{success_count} æ¡åˆ°æ•°æ®åº“
â”œâ”€â”€ æœ€æ–°æ¨æ–‡æ—¶é—´ï¼š{latest_tweet_time or 'æ— '}
â”œâ”€â”€ è€—æ—¶ï¼š{time_cost:.1f} ç§’
        """)

    def save_tweets_to_database(self, tweets: List[Dict[str, Any]]) -> int:
        """æ‰¹é‡ä¿å­˜æ¨æ–‡åˆ°æ•°æ®åº“"""
        if not tweets:
            logging.warning("âš ï¸ æ²¡æœ‰æ–°æ•°æ®éœ€è¦æ’å…¥")
            return 0

        logging.info(f"ğŸ“Š å‡†å¤‡æ’å…¥æ•°æ®åº“çš„æ•°æ®é‡: {len(tweets)} æ¡")

        try:
            if self.db_manager:
                success_count = self.db_manager.save_tweets_batch(tweets)

                # åŒæ—¶ä¿å­˜JSONå¤‡ä»½
                self.save_json_backup(tweets)

                return success_count
            else:
                logging.error("æ•°æ®åº“ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return 0

        except Exception as e:
            logging.error(f"ä¿å­˜æ¨æ–‡æ•°æ®åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}")
            return 0

    def save_json_backup(self, tweets: List[Dict[str, Any]]):
        """ä¿å­˜JSONå¤‡ä»½"""
        try:
            x_config = self.config.get('x', {})
            output_file = x_config.get("output_file", "data/x/tweets.json")
            output_dir = os.path.dirname(output_file)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)

            # è¯»å–ç°æœ‰æ•°æ®
            existing_data = []
            if os.path.exists(output_file):
                with open(output_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)

            # åˆå¹¶æ•°æ®
            all_data = existing_data + tweets

            # å»é‡ï¼ˆåŸºäºtweetUrlï¼‰
            unique_tweets = {}
            for tweet in all_data:
                unique_tweets[tweet['tweetUrl']] = tweet

            # ä¿å­˜æ•°æ®
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(list(unique_tweets.values()), f, ensure_ascii=False, indent=2)

            logging.info(f"JSONå¤‡ä»½å·²ä¿å­˜åˆ° {output_file}")

        except Exception as e:
            logging.error(f"ä¿å­˜JSONå¤‡ä»½å¤±è´¥: {e}")

    def get_users_to_crawl(self) -> List[Dict[str, Any]]:
        """è·å–éœ€è¦çˆ¬å–çš„ç”¨æˆ·åˆ—è¡¨å¹¶åŒ…å«å…¶ä¸ªäººé…ç½®"""
        try:
            users_to_crawl = []
            x_config = self.config.get('x', {})
            config_users = x_config.get("users", [])

            if config_users:
                self.logger.info("ä»é…ç½®æ–‡ä»¶åŠ è½½æŒ‡å®šç”¨æˆ·", user_count=len(config_users))
                if not self.db_manager:
                    self.logger.error("æ•°æ®åº“æœªåˆå§‹åŒ–ï¼Œæ— æ³•è·å–ç”¨æˆ·é…ç½®")
                    return []
                for screen_name in config_users:
                    user_info = self.db_manager.get_user_last_crawl_info(screen_name)
                    if user_info:
                        users_to_crawl.append(user_info)
                    else:
                        self.logger.warning("åœ¨æ•°æ®åº“ä¸­æœªæ‰¾åˆ°é…ç½®çš„ç”¨æˆ·ï¼Œæ— æ³•è·å–å…¶çˆ¬å–é…ç½®", username=screen_name)
            else:
                self.logger.info("é…ç½®æ–‡ä»¶æœªæŒ‡å®šç”¨æˆ·ï¼Œä»æ•°æ®åº“è·å–æ‰€æœ‰å…³æ³¨çš„ç”¨æˆ·")
                if self.db_manager:
                    users_to_crawl = self.db_manager.get_followed_users()

            if not users_to_crawl:
                self.logger.warning("æœªæ‰¾åˆ°éœ€è¦çˆ¬å–çš„ç”¨æˆ·", action="æ£€æŸ¥é…ç½®æˆ–æ•°æ®åº“")
                self.logger.info("é…ç½®æç¤º",
                                 config_location="config.tomlä¸­çš„x.users",
                                 database_setting="member_xè¡¨ä¸­è®¾ç½®follow=1çš„ç”¨æˆ·")
                return []

            self.logger.info(f"å…±æ‰¾åˆ° {len(users_to_crawl)} ä¸ªå¾…çˆ¬å–ç”¨æˆ·")
            for user in users_to_crawl:
                self.logger.info("å¾…çˆ¬å–ç”¨æˆ·",
                                 username=user['screen_name'],
                                 process_retweets=user.get('process_retweets'),
                                 filter_quotes=user.get('filter_quotes'))
            return users_to_crawl

        except Exception as e:
            self.logger.error("è·å–å¾…çˆ¬å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥", error=str(e))
            return []

    def get_my_following_list(self):
        """è·å–æˆ‘çš„å®Œæ•´å…³æ³¨åˆ—è¡¨ - å¾ªç¯è·å–æ‰€æœ‰ç”¨æˆ·"""
        try:
            logging.info("ğŸ” æ­£åœ¨è·å–å®Œæ•´å…³æ³¨åˆ—è¡¨...")

            # è°ƒç”¨Xè®¤è¯å®¢æˆ·ç«¯è·å–å®Œæ•´å…³æ³¨åˆ—è¡¨
            result = self.twitter_client.get_my_following()

            if result and 'users' in result:
                users = result['users']
                logging.info(f"âœ… æˆåŠŸè·å–åˆ° {len(users)} ä¸ªå…³æ³¨ç”¨æˆ·")

                # è½¬æ¢ç”¨æˆ·æ•°æ®æ ¼å¼
                formatted_users = []
                for user in users:
                    formatted_user = {
                        'id_str': user.get('id_str', ''),
                        'screen_name': user.get('screen_name', ''),
                        'name': user.get('name', ''),
                        'description': user.get('description', ''),
                        'followers_count': user.get('followers_count', 0),
                        'friends_count': user.get('friends_count', 0),
                        'statuses_count': user.get('statuses_count', 0),
                        'verified': user.get('verified', False),
                        'profile_image_url_https': user.get('profile_image_url_https', ''),
                        'profile_banner_url': user.get('profile_banner_url', ''),
                        'location': user.get('location', ''),
                        'url': user.get('url', ''),
                        'created_at': user.get('created_at', ''),
                        'protected': user.get('protected', False)
                    }
                    formatted_users.append(formatted_user)

                return {
                    'users': formatted_users,
                    'count': len(formatted_users)
                }
            else:
                logging.error("âŒ è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥")
                return None

        except Exception as e:
            logging.error(f"è·å–å…³æ³¨åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return None

    def run(self):
        """è¿è¡Œçˆ¬è™«ä¸»ç¨‹åº"""
        # è·å–éœ€è¦çˆ¬å–çš„ç”¨æˆ·åˆ—è¡¨åŠå…¶é…ç½®
        users_to_crawl = self.get_users_to_crawl()

        if not users_to_crawl:
            self.logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°éœ€è¦çˆ¬å–çš„ç”¨æˆ·ï¼Œç¨‹åºé€€å‡º")
            return []

        self.logger.info("å¼€å§‹çˆ¬å–ç”¨æˆ·æ¨æ–‡", user_count=len(users_to_crawl))

        all_results = []

        try:
            for user_config in users_to_crawl:
                try:
                    # å¤„ç†å•ä¸ªç”¨æˆ·
                    user_tweets = self.process_user_tweets(user_config)
                    all_results.extend(user_tweets)

                except Exception as e:
                    self.logger.error(f"å¤„ç†ç”¨æˆ· {user_config.get('screen_name')} æ—¶å‡ºé”™", error=str(e))
                    continue

            logging.info(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±å¤„ç† {len(all_results)} æ¡æ¨æ–‡")

        finally:
            if self.db_manager:
                self.db_manager.close()
                logging.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

        return all_results

    def add_user_to_member_x(self, screen_name: str, follow: bool = False) -> bool:
        """
        æ ¹æ®è¾“å…¥çš„screen_nameè‡ªåŠ¨æ’å…¥åˆ°member_xè¡¨ä¸­
        
        Args:
            screen_name: ç”¨æˆ·å
            follow: æ˜¯å¦å…³æ³¨ï¼Œé»˜è®¤ä¸ºFalse
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        try:
            logging.info(f"ğŸ” æ­£åœ¨è·å–ç”¨æˆ· @{screen_name} çš„ä¿¡æ¯...")

            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = self.get_user_info(screen_name, force_refresh=True)
            if not user_info:
                logging.error(f"âŒ æ— æ³•è·å–ç”¨æˆ· @{screen_name} çš„ä¿¡æ¯")
                return False

            # ä½¿ç”¨å®Œæ•´çš„ç”¨æˆ·æ•°æ®
            full_user_data = self.twitter_client.get_user_by_screen_name(screen_name)
            if not full_user_data:
                logging.error(f"âŒ æ— æ³•è·å–ç”¨æˆ· @{screen_name} çš„å®Œæ•´æ•°æ®")
                return False

            # ä¿å­˜åˆ°member_xè¡¨
            success = self.db_manager.save_member(full_user_data, follow=follow)

            if success:
                status = "å…³æ³¨" if follow else "æœªå…³æ³¨"
                logging.info(f"âœ… æˆåŠŸæ·»åŠ ç”¨æˆ· @{screen_name} åˆ°member_xè¡¨ï¼ŒçŠ¶æ€ï¼š{status}")
                return True
            else:
                logging.error(f"âŒ æ·»åŠ ç”¨æˆ· @{screen_name} åˆ°member_xè¡¨å¤±è´¥")
                return False

        except Exception as e:
            logging.error(f"æ·»åŠ ç”¨æˆ· @{screen_name} æ—¶å‡ºé”™: {e}")
            return False

    def sync_following_to_member_x(self) -> int:
        """
        æ ¹æ®current_user_screen_nameè·å–å…³æ³¨åˆ—è¡¨å¹¶æ’å…¥æˆ–ä¿®æ”¹member_xè¡¨
        æ‰€æœ‰å…³æ³¨ç”¨æˆ·çš„followçŠ¶æ€é»˜è®¤ä¸ºtrue
        
        Returns:
            int: æˆåŠŸå¤„ç†çš„ç”¨æˆ·æ•°é‡
        """
        try:
            logging.info("ğŸ”„ å¼€å§‹åŒæ­¥å…³æ³¨åˆ—è¡¨åˆ°member_xè¡¨...")

            # è·å–å®Œæ•´å…³æ³¨åˆ—è¡¨
            following_result = self.get_my_following_list()

            if not following_result or 'users' not in following_result:
                logging.error("âŒ è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥")
                return 0

            users = following_result['users']
            logging.info(f"ğŸ“‹ è·å–åˆ° {len(users)} ä¸ªå…³æ³¨ç”¨æˆ·ï¼Œå¼€å§‹åŒæ­¥åˆ°æ•°æ®åº“...")

            success_count = 0

            for i, user in enumerate(users, 1):
                try:
                    # ä¿å­˜ç”¨æˆ·ä¿¡æ¯åˆ°member_xè¡¨ï¼Œfollow=True
                    success = self.db_manager.save_member(user, follow=True)

                    if success:
                        success_count += 1
                        logging.info(f"   [{i:3d}/{len(users)}] âœ… @{user['screen_name']} - å·²åŒæ­¥")
                    else:
                        logging.warning(f"   [{i:3d}/{len(users)}] âš ï¸ @{user['screen_name']} - åŒæ­¥å¤±è´¥")

                except Exception as e:
                    logging.error(f"   [{i:3d}/{len(users)}] âŒ @{user.get('screen_name', 'unknown')} - é”™è¯¯: {e}")

            logging.info(f"ğŸ‰ åŒæ­¥å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(users)} ä¸ªç”¨æˆ·")

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            total_members = self.db_manager.get_member_count()
            followed_users = self.db_manager.get_followed_users()
            logging.info(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ - æ€»ç”¨æˆ·: {total_members}, å…³æ³¨ç”¨æˆ·: {len(followed_users)}")

            return success_count

        except Exception as e:
            logging.error(f"åŒæ­¥å…³æ³¨åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return 0


if __name__ == "__main__":
    spider = XSpider()
    spider.run()
